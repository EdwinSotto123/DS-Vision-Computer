{"cells":[{"cell_type":"markdown","metadata":{},"source":["Principalmente buscamos resolver el problema de la deteccion de si una planta de tomate esta sana o enferma, para eso hemos planteado usar redes neuronales convolucionales ya que tiene una alta capacidad predictiva para problemas que requieren la clasificacion de imagenes debido a la naturaleza de sus capas convolucionales."]},{"cell_type":"markdown","metadata":{},"source":["## Importando librerías"]},{"cell_type":"markdown","metadata":{},"source":["**Estas bibliotecas son esenciales para el desarrollo y entrenamiento de modelos de aprendizaje automático y redes neuronales. TensorFlow es una de las bibliotecas más ampliamente utilizadas para crear, entrenar y desplegar modelos de aprendizaje profundo. Proporciona un entorno flexible y eficiente para definir y ejecutar operaciones matemáticas en gráficos computacionales, lo que es fundamental para la construcción de redes neuronales.**"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-23T00:32:22.356349Z","iopub.status.busy":"2023-08-23T00:32:22.355417Z","iopub.status.idle":"2023-08-23T00:32:22.369879Z","shell.execute_reply":"2023-08-23T00:32:22.369107Z","shell.execute_reply.started":"2023-08-23T00:32:22.356305Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd \n","import random\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix , classification_report\n","from tensorflow.keras import models, layers\n","from tensorflow import keras\n","from tensorflow.keras.layers import Input, Lambda, Flatten, Reshape, Conv2D, MaxPooling2D, Dropout, Activation, BatchNormalization\n","from tensorflow.keras.layers import Dense, Concatenate, Add, Reshape, Dot\n","from tensorflow.keras.models import Sequential,Model\n","from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n","from keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, array_to_img, img_to_array\n","from keras.applications.vgg19 import VGG19\n","from tensorflow.keras.models import load_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:22.372533Z","iopub.status.busy":"2023-08-23T00:32:22.372239Z","iopub.status.idle":"2023-08-23T00:32:22.405649Z","shell.execute_reply":"2023-08-23T00:32:22.404890Z","shell.execute_reply.started":"2023-08-23T00:32:22.372489Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","\n","# Ruta de la imagen\n","image_path = '/kaggle/input/tomatecorregido/Tomatos/TEST/Healthy/0031da2a-8edd-468f-a8b1-106657717a32___RS_HL 0105.JPG'\n","\n","# Abrir la imagen con PIL\n","image = Image.open(image_path)\n","\n","# Obtener el tamaño de píxeles\n","width, height = image.size\n","\n","# Imprimir el tamaño de píxeles\n","print(\"Ancho:\", width)\n","print(\"Alto:\", height)"]},{"cell_type":"markdown","metadata":{},"source":["## Creación del modelo convolucional"]},{"cell_type":"markdown","metadata":{},"source":["****Una CNN es un tipo de red neuronal especialmente diseñada para procesar datos con una estructura de cuadrícula, como imágenes. La arquitectura definida aquí consta de varias capas convolucionales intercaladas con capas de normalización y agrupación (pooling), seguidas de capas completamente conectadas.**\n","\n","**En cada bloque de capas convolucionales, se realizan operaciones de convolución y activación ReLU para extraer características de la imagen. La capa de normalización BatchNormalization ayuda a estabilizar y acelerar el entrenamiento de la red, y la capa de agrupación MaxPooling reduce el tamaño de las representaciones para mantener un procesamiento eficiente. Los bloques convolucionales se escalan gradualmente, aumentando el número de filtros para capturar características más abstractas.\n","**\n","Después de las capas convolucionales, se añade una capa Flatten para aplanar los datos y luego se conecta a capas completamente conectadas. Una capa Dense con 512 unidades y activación ReLU ayuda a aprender representaciones más abstractas y complejas de los datos. Se aplica un Dropout del 20% para evitar el sobreajuste durante el entrenamiento. Finalmente, hay una capa Dense con una sola unidad y activación sigmoide para la clasificación binaria, donde se intenta distinguir entre dos clases, en este caso \"Tomate sano\" y \"Tomate enfermo\".**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:22.407771Z","iopub.status.busy":"2023-08-23T00:32:22.407236Z","iopub.status.idle":"2023-08-23T00:32:22.632189Z","shell.execute_reply":"2023-08-23T00:32:22.631379Z","shell.execute_reply.started":"2023-08-23T00:32:22.407729Z"},"trusted":true},"outputs":[],"source":["model = models.Sequential()\n","\n","model.add(Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(64, (3,3), activation='relu'))\n","model.add(Conv2D(64, (3,3), activation='relu'))\n","model.add(MaxPooling2D((2,2), padding='same'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(128, (3,3), activation='relu'))\n","model.add(Conv2D(128, (3,3), activation='relu'))\n","model.add(MaxPooling2D((2,2)))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(256, (3,3), activation='relu'))\n","model.add(Conv2D(256, (3,3), activation='relu'))\n","model.add(MaxPooling2D((2,2)))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(512, (3,3), activation='relu',  padding='same'))\n","model.add(Conv2D(512, (3,3), activation='relu',  padding='same'))\n","model.add(MaxPooling2D((2,2), padding='same'))\n","model.add(BatchNormalization())\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.summary()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data augmentation"]},{"cell_type":"markdown","metadata":{},"source":["La instancia de ImageDataGenerator de TensorFlow se utiliza para aplicar diversas transformaciones a las imágenes durante el entrenamiento. Las transformaciones incluyen rotación aleatoria, desplazamiento horizontal y vertical, corte (shearing), zoom y volteo horizontal. Cada vez que una imagen se pasa a través del generador durante el entrenamiento, se aplica una combinación aleatoria de estas transformaciones, lo que resulta en imágenes ligeramente diferentes."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:22.635568Z","iopub.status.busy":"2023-08-23T00:32:22.635345Z","iopub.status.idle":"2023-08-23T00:32:22.644091Z","shell.execute_reply":"2023-08-23T00:32:22.643311Z","shell.execute_reply.started":"2023-08-23T00:32:22.635540Z"},"trusted":true},"outputs":[],"source":["##APLICAMOS LA TECNICA DE AUMENTADO DE DATOS A CADA IMAGEN\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n","    )\n","\n","train_path=\"/kaggle/input/tomateus/tomato_dataset/train\"\n","valid_path=\"/kaggle/input/tomateus/tomato_dataset/valid\"\n","test_path=\"/kaggle/input/tomateus/tomato_dataset/test\""]},{"cell_type":"markdown","metadata":{},"source":["## Reescalar los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:22.647241Z","iopub.status.busy":"2023-08-23T00:32:22.646680Z","iopub.status.idle":"2023-08-23T00:32:22.654428Z","shell.execute_reply":"2023-08-23T00:32:22.653601Z","shell.execute_reply.started":"2023-08-23T00:32:22.647203Z"},"trusted":true},"outputs":[],"source":["valid_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale = 1./255)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:22.656214Z","iopub.status.busy":"2023-08-23T00:32:22.655834Z","iopub.status.idle":"2023-08-23T00:32:24.636312Z","shell.execute_reply":"2023-08-23T00:32:24.635407Z","shell.execute_reply.started":"2023-08-23T00:32:22.656178Z"},"trusted":true},"outputs":[],"source":["##Hacemos el data aumentation para imagenes de la carpeta TRAIN\n","train_set = train_datagen.flow_from_directory(train_path,\n","                                 target_size=(256,256),\n","                                 batch_size=32, ##Tamaño de lote de cada iteracion\n","                                 class_mode='binary', ##Clasificacion de tipo binaria\n","                                 shuffle=True\n","                                 )\n","##Hacemos el data aumentation para imagenes de la carpeta VALIDATION\n","valid_set = valid_datagen.flow_from_directory(valid_path,\n","                                 target_size=(256,256),\n","                                 batch_size=32, ##Tamaño de lote de cada iteracion\n","                                 class_mode='binary', ##Clasificacion de tipo binaria\n","                                shuffle=True\n","                                 )\n","test_set = test_datagen.flow_from_directory(test_path,\n","                                            target_size=(256,256),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary',\n","                                           shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Callbacks"]},{"cell_type":"markdown","metadata":{},"source":["Este callback ajusta automáticamente la tasa de aprendizaje del optimizador en función de la disminución de la pérdida durante el entrenamiento. Si la pérdida no mejora después de un número específico de épocas (patience), la tasa de aprendizaje se reduce multiplicándola por un factor (factor). Esto permite un ajuste más preciso del proceso de entrenamiento, aumentando gradualmente la tasa de aprendizaje si el modelo se encuentra en una región de pérdida alta y disminuyéndola cuando se alcanza una meseta en el proceso de optimización. El valor mínimo de la tasa de aprendizaje se establece en 0.00001 para evitar que disminuya indefinidamente."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:24.639511Z","iopub.status.busy":"2023-08-23T00:32:24.638673Z","iopub.status.idle":"2023-08-23T00:32:24.645896Z","shell.execute_reply":"2023-08-23T00:32:24.644874Z","shell.execute_reply.started":"2023-08-23T00:32:24.639470Z"},"trusted":true},"outputs":[],"source":["##CREAMOS UN DIRECTORIO DE SALIDA QUE GUARDE EL MODELO(LOS PESOS) QUE OBTENGA MEJOR RESULTADO AL ENTRENAR EL MODELO\n","\n","from keras.callbacks import ReduceLROnPlateau\n","learning_rate_reduction = ReduceLROnPlateau(monitor='loss'\n","                                            , patience = 2\n","                                            , verbose=1\n","                                            ,factor=0.75\n","                                            , min_lr=0.00001)"]},{"cell_type":"markdown","metadata":{},"source":["## Entrenando el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T00:32:24.647624Z","iopub.status.busy":"2023-08-23T00:32:24.647289Z","iopub.status.idle":"2023-08-23T01:52:49.986061Z","shell.execute_reply":"2023-08-23T01:52:49.985290Z","shell.execute_reply.started":"2023-08-23T00:32:24.647583Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.optimizers import RMSprop\n","model.compile(optimizer=RMSprop(learning_rate=0.001),\n","              loss='binary_crossentropy',\n","              metrics=[\"accuracy\"]\n","              \n",")\n","\n","epochs = 100\n","\n","hist = model.fit(train_set,\n","                                    steps_per_epoch=len(train_set),  \n","                                    validation_data=valid_set,\n","                                epochs=100,\n","                                callbacks=[learning_rate_reduction],\n","                                validation_steps=len(valid_set),\n","                                verbose=1,\n","                            )"]},{"cell_type":"markdown","metadata":{},"source":["## Resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:52:49.987955Z","iopub.status.busy":"2023-08-23T01:52:49.987653Z","iopub.status.idle":"2023-08-23T01:52:59.011972Z","shell.execute_reply":"2023-08-23T01:52:59.011274Z","shell.execute_reply.started":"2023-08-23T01:52:49.987917Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","scores2 = model.evaluate(test_set)\n","scores2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:52:59.013657Z","iopub.status.busy":"2023-08-23T01:52:59.013385Z","iopub.status.idle":"2023-08-23T01:53:02.840991Z","shell.execute_reply":"2023-08-23T01:53:02.840224Z","shell.execute_reply.started":"2023-08-23T01:52:59.013621Z"},"trusted":true},"outputs":[],"source":["scores1 = model.evaluate(valid_set)\n","scores1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:02.844033Z","iopub.status.busy":"2023-08-23T01:53:02.842403Z","iopub.status.idle":"2023-08-23T01:53:03.083227Z","shell.execute_reply":"2023-08-23T01:53:03.082518Z","shell.execute_reply.started":"2023-08-23T01:53:02.843988Z"},"trusted":true},"outputs":[],"source":["##MOSTRAMOS LA VARIACION ENTRE EL ACURRACY DE ENTRENAMIENTO Y VALIDACION\n","plt.plot(hist.history['accuracy'], label = 'Train')\n","plt.plot(hist.history['val_accuracy'], label = 'Val')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:03.085188Z","iopub.status.busy":"2023-08-23T01:53:03.084692Z","iopub.status.idle":"2023-08-23T01:53:03.308284Z","shell.execute_reply":"2023-08-23T01:53:03.307563Z","shell.execute_reply.started":"2023-08-23T01:53:03.085149Z"},"trusted":true},"outputs":[],"source":["##MOSTRAMOS LA VARIACION ENTRE EL ACURRACY DE ENTRENAMIENTO Y VALIDACION\n","plt.plot(hist.history['loss'], label = 'Train')\n","plt.plot(hist.history['val_loss'], label = 'Val')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:03.310854Z","iopub.status.busy":"2023-08-23T01:53:03.309611Z","iopub.status.idle":"2023-08-23T01:53:03.316984Z","shell.execute_reply":"2023-08-23T01:53:03.316219Z","shell.execute_reply.started":"2023-08-23T01:53:03.310812Z"},"trusted":true},"outputs":[],"source":["class_names = list(train_set.class_indices.keys())\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:03.320786Z","iopub.status.busy":"2023-08-23T01:53:03.320546Z","iopub.status.idle":"2023-08-23T01:53:03.328950Z","shell.execute_reply":"2023-08-23T01:53:03.328205Z","shell.execute_reply.started":"2023-08-23T01:53:03.320744Z"},"trusted":true},"outputs":[],"source":["def predict(model, img):\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array = tf.expand_dims(img_array, 0)\n","\n","    predictions = model.predict(img_array)\n","    confidence = round(100 * predictions[0][0], 2)\n","\n","    if predictions[0][0] < 0.5:\n","        predicted_class = class_names[0]\n","        confidence = round(100 - confidence, 2)\n","    else:\n","        predicted_class = class_names[1]\n","    \n","    return predicted_class, confidence"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:03.330535Z","iopub.status.busy":"2023-08-23T01:53:03.330270Z","iopub.status.idle":"2023-08-23T01:53:05.313083Z","shell.execute_reply":"2023-08-23T01:53:05.310781Z","shell.execute_reply.started":"2023-08-23T01:53:03.330492Z"},"trusted":true},"outputs":[],"source":["c"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:05.314363Z","iopub.status.busy":"2023-08-23T01:53:05.314095Z","iopub.status.idle":"2023-08-23T01:53:05.429046Z","shell.execute_reply":"2023-08-23T01:53:05.428219Z","shell.execute_reply.started":"2023-08-23T01:53:05.314330Z"},"trusted":true},"outputs":[],"source":["valid_set1 = valid_datagen.flow_from_directory(valid_path,\n","                                            target_size = (256,256),\n","                                            batch_size = 64,\n","                                            class_mode = 'binary',\n","                                             shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["valid_set1 = valid_datagen.flow_from_directory(valid_path,\n","                                            target_size = (256,256),\n","                                            batch_size = 64,\n","                                            class_mode = 'binary',\n","                                             shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:05.431036Z","iopub.status.busy":"2023-08-23T01:53:05.430550Z","iopub.status.idle":"2023-08-23T01:53:18.560083Z","shell.execute_reply":"2023-08-23T01:53:18.559278Z","shell.execute_reply.started":"2023-08-23T01:53:05.430995Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import load_model\n","# Obtener las predicciones\n","Y_pred = model.predict(valid_set1)\n","y_pred = (Y_pred > 0.5).astype(int)  # Convertir probabilidades a etiquetas binarias (0 o 1)\n","y_true = valid_set1.classes\n","class_names = list(valid_set1.class_indices.keys())\n","\n","# Calcular el informe de clasificación\n","report = classification_report(y_true, y_pred, target_names=class_names)\n","\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:18.562208Z","iopub.status.busy":"2023-08-23T01:53:18.561747Z","iopub.status.idle":"2023-08-23T01:53:22.472321Z","shell.execute_reply":"2023-08-23T01:53:22.471626Z","shell.execute_reply.started":"2023-08-23T01:53:18.562152Z"},"trusted":true},"outputs":[],"source":["##OBSERVAR LOS PRIMEROS 32 KERNEL Y SU EFECTO EN LAS IMAGENES DE NUESTRA CAPA CONVOLUCIONAL\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import load_img\n","import numpy as np\n","\n","# Obtener los pesos de la primera capa convolucional\n","weights = model.layers[0].get_weights()[0]\n","\n","# Visualizar los filtros\n","fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n","for i in range(4):\n","    for j in range(8):\n","        axs[i, j].imshow(weights[:, :, 0, i*8+j], cmap='viridis')  # Se asume que los filtros son de tamaño 3D (alto x ancho x canales)\n","        axs[i, j].axis('off')\n","plt.tight_layout()\n","plt.show()\n","\n","# Cargar y preprocesar una imagen de muestra\n","image_path = \"/kaggle/input/tomatecorregido/Tomatos/TEST/Healthy/0031da2a-8edd-468f-a8b1-106657717a32___RS_HL 0105.JPG\"  # Ruta de la imagen que deseas procesar\n","\n","def preprocess_image(image_path):\n","    image = load_img(image_path, target_size=(256, 256))\n","    image = np.array(image) / 255.0  # Normalizar la imagen\n","    image = np.expand_dims(image, axis=0)\n","    return image\n","\n","image = preprocess_image(image_path)\n","\n","# Obtener las feature maps\n","layer_outputs = [layer.output for layer in model.layers[:4]]  # Obtener las salidas de las capas convolucionales\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","feature_maps = activation_model.predict(image)\n","\n","# Visualizar las feature maps\n","fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n","for i in range(4):\n","    for j in range(8):\n","        axs[i, j].imshow(feature_maps[i][0, :, :, j], cmap='viridis')  # Se asume que las feature maps son de tamaño 3D (alto x ancho x canales)\n","        axs[i, j].axis('off')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:22.474147Z","iopub.status.busy":"2023-08-23T01:53:22.473521Z","iopub.status.idle":"2023-08-23T01:53:22.510040Z","shell.execute_reply":"2023-08-23T01:53:22.508654Z","shell.execute_reply.started":"2023-08-23T01:53:22.474103Z"},"trusted":true},"outputs":[],"source":["##OBSERVAMOS LOS KERNELS DE MANERA MATRICIAL\n","# Obtener los pesos de la primera capa convolucional\n","weights = model.layers[0].get_weights()[0]\n","\n","# Obtener las dimensiones de los filtros\n","num_filters = weights.shape[3]\n","filter_size = weights.shape[0]\n","\n","# Mostrar las matrices de los kernels\n","for i in range(num_filters):\n","    print(\"Kernel {}:\".format(i+1))\n","    print(weights[:, :, 0, i])\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:22.512048Z","iopub.status.busy":"2023-08-23T01:53:22.511374Z","iopub.status.idle":"2023-08-23T01:53:23.335022Z","shell.execute_reply":"2023-08-23T01:53:23.334168Z","shell.execute_reply.started":"2023-08-23T01:53:22.512008Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Directorio donde se encuentran las imágenes originales\n","original_images_dir = '/kaggle/input/tomatecorregido/Tomatos/TEST/Healthy'\n","\n","# Cargar la imagen original\n","original_image_path = '/kaggle/input/tomatecorregido/Tomatos/TEST/Healthy/0031da2a-8edd-468f-a8b1-106657717a32___RS_HL 0105.JPG'\n","original_image = plt.imread(original_image_path)\n","\n","# Normalizar la escala de los píxeles\n","original_image = original_image / 255.0\n","\n","# Definir las transformaciones de aumento de datos\n","data_augmentation = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    vertical_flip=True\n",")\n","\n","# Mostrar las imágenes con las transformaciones\n","fig, ax = plt.subplots(2, 3, figsize=(12, 8))\n","\n","# Mostrar la imagen original\n","ax[0, 0].imshow(original_image)\n","ax[0, 0].set_title('Original')\n","ax[0, 0].axis('off')\n","\n","# Generar y mostrar las imágenes aumentadas\n","i = 0\n","for batch in data_augmentation.flow(original_image.reshape(1, *original_image.shape), batch_size=1):\n","    image = batch[0]\n","    row = i // 3\n","    col = i % 3\n","    ax[row, col].imshow(image)\n","    ax[row, col].set_title(f'Transformation {i+1}')\n","    ax[row, col].axis('off')\n","    i += 1\n","    if i >= 6:\n","        break\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:23.336529Z","iopub.status.busy":"2023-08-23T01:53:23.336155Z","iopub.status.idle":"2023-08-23T01:53:24.589216Z","shell.execute_reply":"2023-08-23T01:53:24.588622Z","shell.execute_reply.started":"2023-08-23T01:53:23.336495Z"},"trusted":true},"outputs":[],"source":["###PROBAR CON DATOS DE INTERNET\n","import urllib.request\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","# Definir la URL de la imagen\n","image_url = 'https://www.elhuertourbano.net/wp-content/uploads/plantas-y-flores-de-tomatera-1.jpg'\n","\n","# Descargar la imagen desde la URL\n","urllib.request.urlretrieve(image_url, 'image.jpg')\n","\n","# Cargar la imagen descargada usando PIL\n","image = Image.open('image.jpg')\n","\n","# Convertir la imagen a modo RGB si tiene un canal adicional (alfa)\n","if image.mode == 'RGBA':\n","    image = image.convert('RGB')\n","\n","# Redimensionar la imagen a las dimensiones requeridas por tu modelo\n","# Puedes ajustar las dimensiones según las necesidades de tu modelo\n","image = image.resize((256, 256))\n","\n","# Convertir la imagen a un arreglo NumPy\n","image_array = np.array(image)\n","\n","# Preprocesar la imagen según los requisitos de tu modelo\n","# Por ejemplo, normalizar los valores de píxeles\n","preprocessed_image = image_array / 255.0\n","\n","# Mostrar la imagen\n","plt.imshow(preprocessed_image)\n","plt.axis('off')\n","plt.show()\n","\n","# Hacer la predicción con tu modelo\n","prediction = model.predict(np.expand_dims(preprocessed_image, axis=0))\n","prediction[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:24.591404Z","iopub.status.busy":"2023-08-23T01:53:24.590907Z","iopub.status.idle":"2023-08-23T01:53:25.040586Z","shell.execute_reply":"2023-08-23T01:53:25.039752Z","shell.execute_reply.started":"2023-08-23T01:53:24.591363Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from keras.preprocessing.image import load_img, img_to_array\n","import matplotlib.pyplot as plt\n","\n","def preprocess_image1(image_path3):\n","    img = load_img(image_path3, target_size=(256, 256))\n","    img = img_to_array(img)\n","    img = img / 255.0\n","    img = np.expand_dims(img, axis=0)\n","    return img\n","\n","def predict_image(image_path3):\n","    img = preprocess_image1(image_path3)\n","    prediction = model.predict(img)\n","    if prediction[0][0] < 0.5:\n","        prediction_text = \"Tomate sano\"\n","    else:\n","        prediction_text = \"Tomate enfermo\"\n","    return prediction_text, img[0]\n","\n","# Ruta de la imagen a predecir\n","image_path3 = '/kaggle/input/dadaaff/WhatsApp Image 2023-06-30 at 1.07.54 PM.jpeg'\n","\n","# Realizar la predicción\n","prediction_text, predicted_image = predict_image(image_path3)\n","\n","# Mostrar el resultado\n","fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 8))\n","\n","# Mostrar la imagen con el texto de predicción\n","ax1.imshow(predicted_image)\n","ax1.set_title(prediction_text)\n","ax1.axis('off')\n","\n","# Mostrar solo la imagen\n","ax2.imshow(predicted_image)\n","ax2.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:25.042311Z","iopub.status.busy":"2023-08-23T01:53:25.041924Z","iopub.status.idle":"2023-08-23T01:53:25.158322Z","shell.execute_reply":"2023-08-23T01:53:25.157627Z","shell.execute_reply.started":"2023-08-23T01:53:25.042276Z"},"trusted":true},"outputs":[],"source":["valid_set1 = valid_datagen.flow_from_directory(valid_path,\n","                                            target_size = (256,256),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary',\n","                                             shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:25.164458Z","iopub.status.busy":"2023-08-23T01:53:25.162425Z","iopub.status.idle":"2023-08-23T01:53:30.503692Z","shell.execute_reply":"2023-08-23T01:53:30.502924Z","shell.execute_reply.started":"2023-08-23T01:53:25.164417Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import load_model\n","# Obtener las predicciones\n","Y_pred = model.predict(valid_set1)\n","y_pred = (Y_pred > 0.5).astype(int)  # Convertir probabilidades a etiquetas binarias (0 o 1)\n","y_true = valid_set1.classes\n","class_names = list(valid_set1.class_indices.keys())\n","\n","# Calcular el informe de clasificación\n","report = classification_report(y_true, y_pred, target_names=class_names)\n","\n","print(report)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-23T01:53:30.505842Z","iopub.status.busy":"2023-08-23T01:53:30.504912Z","iopub.status.idle":"2023-08-23T01:53:31.410589Z","shell.execute_reply":"2023-08-23T01:53:31.409763Z","shell.execute_reply.started":"2023-08-23T01:53:30.505801Z"},"trusted":true},"outputs":[],"source":["model.save('model.h5')"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":145158,"sourceId":338958,"sourceType":"datasetVersion"},{"datasetId":3392260,"sourceId":5907401,"sourceType":"datasetVersion"},{"datasetId":3466715,"sourceId":6058333,"sourceType":"datasetVersion"},{"datasetId":3467429,"sourceId":6059410,"sourceType":"datasetVersion"},{"datasetId":3467519,"sourceId":6059552,"sourceType":"datasetVersion"},{"datasetId":3626671,"sourceId":6304065,"sourceType":"datasetVersion"},{"datasetId":3626673,"sourceId":6304074,"sourceType":"datasetVersion"}],"dockerImageVersionId":30140,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
